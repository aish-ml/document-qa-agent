"""
Streamlit Chat UI for Document Q&A AI Agent
============================================
Beautiful, interactive web interface for document ingestion,
Arxiv search + auto-ingest, and conversational Q&A.

Run with:
    streamlit run ui/streamlit_app.py
"""

import sys
import time
import threading
from pathlib import Path

# â”€â”€ Ensure project root is importable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import streamlit as st

# â”€â”€ Page Config (MUST be first Streamlit call) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Document Q&A Agent",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded",
)

from config import (
    DOCUMENTS_DIR,
    LLM_PROVIDER,
    AUTO_INGEST_ON_START,
    ARXIV_AUTO_INGEST_TOPN,
)
from utils.helpers import setup_logging
from knowledge_base.vector_store import VectorStore
from agent.qa_agent import QAAgent
from ingestion.pdf_extractor import PDFExtractor
from ingestion.chunker import DocumentChunker
from arxiv_integration.arxiv_client import ArxivClient

setup_logging("INFO")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Cached Singletons (survive Streamlit reruns)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource(show_spinner="Initializing vector storeâ€¦")
def _get_vector_store() -> VectorStore:
    return VectorStore()


@st.cache_resource(show_spinner="Loading AI agentâ€¦")
def _get_agent(_vs: VectorStore) -> QAAgent:
    return QAAgent(vector_store=_vs)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Background Ingest Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _run_pdf_ingest(vs: VectorStore, pdf_paths: list[str], key: str):
    """Ingest PDFs in a background thread, updating session_state."""
    try:
        extractor = PDFExtractor(save_images=True)
        chunker = DocumentChunker()
        total = 0
        details = []

        for i, p in enumerate(pdf_paths):
            fname = Path(p).name
            st.session_state[key] = f"Extracting {fname}â€¦ ({i+1}/{len(pdf_paths)})"
            try:
                doc = extractor.extract(p)
                chunks = chunker.chunk_document(doc)
                count = vs.add_chunks(chunks)
                total += count
                details.append(
                    f"âœ… {fname} â€” {doc.total_pages} pages, "
                    f"{len(doc.tables)} tables, {count} chunks"
                )
            except Exception as e:
                details.append(f"âŒ {fname} â€” {e}")

        st.session_state[key] = "done"
        st.session_state[f"{key}_result"] = {"total": total, "details": details}
    except Exception as e:
        st.session_state[key] = f"error: {e}"


def _run_arxiv_ingest(vs: VectorStore, papers: list, key: str):
    """Download + ingest Arxiv papers in a background thread."""
    try:
        client = ArxivClient()
        extractor = PDFExtractor(save_images=True)
        chunker = DocumentChunker()
        total = 0
        details = []

        for i, paper in enumerate(papers):
            short = paper.title[:55]
            st.session_state[key] = f"Downloading {short}â€¦ ({i+1}/{len(papers)})"
            pdf_path = client.download_pdf(paper, str(DOCUMENTS_DIR))
            if not pdf_path:
                details.append(f"âŒ {short} â€” download failed")
                continue
            try:
                doc = extractor.extract(pdf_path)
                chunks = chunker.chunk_document(doc)
                count = vs.add_chunks(chunks)
                total += count
                details.append(f"âœ… {short} â€” {doc.total_pages}p, {count} chunks")
            except Exception as e:
                details.append(f"âŒ {short} â€” {e}")

        st.session_state[key] = "done"
        st.session_state[f"{key}_result"] = {"total": total, "details": details}
    except Exception as e:
        st.session_state[key] = f"error: {e}"


def _launch_job(target, args, key):
    """Start a daemon thread for background work."""
    st.session_state[key] = "startingâ€¦"
    t = threading.Thread(target=target, args=args, daemon=True)
    t.start()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Session State Defaults
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_DEFAULTS = {
    "messages": [],
    "arxiv_results": [],
    "auto_ingested": False,
}
for k, v in _DEFAULTS.items():
    if k not in st.session_state:
        st.session_state[k] = v


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Initialize Backend
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vs = _get_vector_store()
agent = _get_agent(vs)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Auto-Ingest on First Load
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if AUTO_INGEST_ON_START and not st.session_state.auto_ingested:
    pdfs = sorted(DOCUMENTS_DIR.glob("*.pdf"))
    if pdfs:
        existing = set(vs.list_sources())
        new_pdfs = [str(p) for p in pdfs if p.name not in existing]
        if new_pdfs:
            st.session_state.auto_ingested = True
            _launch_job(_run_pdf_ingest, (vs, new_pdfs, "auto_status"), "auto_status")
        else:
            st.session_state.auto_ingested = True
    else:
        st.session_state.auto_ingested = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Custom CSS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown(
    """
    <style>
    /* Sidebar width */
    [data-testid="stSidebar"] { min-width: 340px; max-width: 420px; }

    /* Chat messages */
    .stChatMessage { border-radius: 12px; margin-bottom: 8px; }

    /* Source badges */
    .source-badge {
        display: inline-block;
        background: #e8f4f8;
        color: #1a5276;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 0.82em;
        margin: 2px 4px 2px 0;
    }

    /* Status banner */
    .ingest-status {
        padding: 10px 14px;
        border-radius: 8px;
        margin-bottom: 12px;
        font-size: 0.9em;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Status Banners (background jobs)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _show_status(key: str, label: str):
    """Render a status banner and auto-rerun while busy."""
    status = st.session_state.get(key)
    if not status:
        return
    if status == "done":
        result = st.session_state.get(f"{key}_result", {})
        total = result.get("total", 0)
        details = result.get("details", [])
        with st.expander(f"âœ… {label} complete â€” {total} chunks added", expanded=True):
            for d in details:
                st.markdown(d)
            if st.button("Dismiss", key=f"dismiss_{key}"):
                for k2 in (key, f"{key}_result"):
                    st.session_state.pop(k2, None)
                st.rerun()
    elif status.startswith("error"):
        st.error(f"{label}: {status}")
    else:
        st.info(f"â³ **{label}:** {status}")
        time.sleep(1.5)
        st.rerun()


_show_status("auto_status", "Auto-Ingest")
_show_status("upload_status", "Upload Ingest")
_show_status("folder_status", "Folder Ingest")
_show_status("arxiv_status", "Arxiv Download & Ingest")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Sidebar
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.sidebar:
    st.markdown("## ğŸ“„ Document Q&A Agent")
    st.caption(f"Provider: **{LLM_PROVIDER}** &nbsp;|&nbsp; Chunks: **{vs.count}**")

    # â”€â”€ Knowledge Base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“š Knowledge Base")
    sources = vs.list_sources()
    if sources:
        for s in sources:
            st.markdown(f"- `{s}`")
    else:
        st.info("No documents loaded yet. Upload PDFs or use Arxiv search below.")

    st.divider()

    # â”€â”€ Upload PDFs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### â¬†ï¸ Upload PDFs")
    uploaded_files = st.file_uploader(
        "Drop PDF files here",
        type=["pdf"],
        accept_multiple_files=True,
        label_visibility="collapsed",
    )
    if uploaded_files:
        if st.button("ğŸ“¥ Ingest uploaded files", type="primary", use_container_width=True):
            paths = []
            for f in uploaded_files:
                dest = DOCUMENTS_DIR / f.name
                dest.write_bytes(f.getvalue())
                paths.append(str(dest))
            _launch_job(_run_pdf_ingest, (vs, paths, "upload_status"), "upload_status")
            st.rerun()

    # â”€â”€ Ingest documents/ folder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“‚ documents/ Folder")
    if st.button("Ingest all PDFs in documents/", use_container_width=True):
        pdfs = sorted(DOCUMENTS_DIR.glob("*.pdf"))
        if pdfs:
            _launch_job(
                _run_pdf_ingest,
                (vs, [str(p) for p in pdfs], "folder_status"),
                "folder_status",
            )
            st.rerun()
        else:
            st.warning("No PDFs found in documents/ folder.")

    st.divider()

    # â”€â”€ Arxiv Search + Auto-Ingest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ” Arxiv Search")
    arxiv_query = st.text_input(
        "Search query",
        placeholder="e.g. large language models 2024",
        label_visibility="collapsed",
    )
    col1, col2 = st.columns([2, 1])
    with col2:
        arxiv_topn = st.number_input("Top N", 1, 20, ARXIV_AUTO_INGEST_TOPN, label_visibility="collapsed")
    with col1:
        do_search = st.button("ğŸ” Search", use_container_width=True)

    if do_search and arxiv_query:
        with st.spinner("Searching Arxivâ€¦"):
            client = ArxivClient(max_results=int(arxiv_topn))
            papers = client.search(arxiv_query)
            st.session_state.arxiv_results = papers
            if not papers:
                st.warning("No papers found.")
            st.rerun()

    # â”€â”€ Display Arxiv results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.arxiv_results:
        papers = st.session_state.arxiv_results
        st.success(f"Found **{len(papers)}** papers")
        for i, p in enumerate(papers):
            with st.expander(f"{i+1}. {p.title[:75]}", expanded=False):
                st.markdown(f"**Authors:** {', '.join(p.authors[:4])}")
                st.markdown(f"**Published:** {p.published} &nbsp;|&nbsp; **ID:** `{p.arxiv_id}`")
                st.markdown(f"[ğŸ“¥ PDF]({p.pdf_url})")
                st.caption(
                    p.abstract[:280] + "â€¦" if len(p.abstract) > 280 else p.abstract
                )

        if st.button(
            f"â¬‡ï¸ Download & Ingest All {len(papers)} Papers",
            type="primary",
            use_container_width=True,
        ):
            _launch_job(
                _run_arxiv_ingest,
                (vs, papers, "arxiv_status"),
                "arxiv_status",
            )
            st.session_state.arxiv_results = []
            st.rerun()

        if st.button("Clear results", use_container_width=True):
            st.session_state.arxiv_results = []
            st.rerun()

    st.divider()

    # â”€â”€ Controls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### âš™ï¸ Controls")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ—‘ï¸ Clear chat", use_container_width=True):
            st.session_state.messages = []
            agent.clear_history()
            st.rerun()
    with c2:
        if st.button("ğŸ—„ï¸ Reset KB", use_container_width=True):
            vs.clear()
            st.session_state.messages = []
            agent.clear_history()
            st.rerun()

    # â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("ğŸ“Š Agent Stats"):
        stats = agent.get_stats()
        for k, v in stats.items():
            st.markdown(f"**{k}:** `{v}`")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Chat Area
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.header("ğŸ’¬ Ask your Documents")

if not sources:
    st.info(
        "ğŸ‘ˆ **Get started:** Upload PDFs in the sidebar, click "
        "\"Ingest all PDFs\", or search Arxiv to download papers."
    )

# â”€â”€ Render conversation history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="ğŸ§‘â€ğŸ’»" if msg["role"] == "user" else "ğŸ¤–"):
        st.markdown(msg["content"])
        if msg.get("sources"):
            src_html = " ".join(
                f'<span class="source-badge">ğŸ“„ {s}</span>' for s in msg["sources"]
            )
            st.markdown(src_html, unsafe_allow_html=True)

# â”€â”€ Chat input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if prompt := st.chat_input("Ask a question about your documentsâ€¦"):
    # Append & render user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt)

    # Get agent response
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("Thinkingâ€¦"):
            response = agent.ask(prompt)

        answer = response.get("answer", "I couldn't find an answer.")
        st.markdown(answer)

        srcs = response.get("sources", [])
        if srcs:
            src_html = " ".join(
                f'<span class="source-badge">ğŸ“„ {s}</span>' for s in srcs
            )
            st.markdown(src_html, unsafe_allow_html=True)

    # Save assistant message
    st.session_state.messages.append({
        "role": "assistant",
        "content": answer,
        "sources": srcs,
    })
